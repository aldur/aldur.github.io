---
title: 'Nuggets of psychology'
excerpt: >
  A living collection of psychological mental models for making better decisions.
---

Understanding the world requires seeking good explanations, not fooling
oneself, and figuring out _why_ things truly happen. Only this way we can do
better next time.

In my quest to achieve this, I have found that many mental models are rooted in
psychology. They start right there and lean into marketing, behavioral
economics, product management, negotiation, and even how we approach everyday
tasks.

This living post collects those _nuggets_ of psychology I wish to remember and
add to my _latticework_ of mental models. I have learned them from multiple
authors and books: _Thinking Fast and Slow_, _The Paradox of Choice_, _Poor
Charlie's Almanack_, and more. In describing them here, I will make
simplifications that might make experts shiver. If you find something that
interests you and you want to dive into it, start out with those books – or
better yet, the original research. And if you spot any mistake or
over-simplification, please do reach out and let me know!

<!-- prettier-ignore-start -->

- Table of Contents
{:toc}
<!-- prettier-ignore-end -->

#### The paradox of choice

It is much easier to spend several hours binge-watching a TV series than to
pick a good movie and commit a couple of hours to it. Why? Because freedom of
choice can lead to difficult decisions and, sometimes, to less happiness.

If you have already watched a few episodes of a show, you know what to expect
from it. If you have previously enjoyed it, you expect to continue doing so.
Instead, modern streaming platforms encourage us to pick a movie among
hundreds. It is much easier to decide _not_ to pick and just watch another
episode of that familiar show.

When we do try picking something, we face uncertainty and we fear regret: "What
if I pick a worse movie than the TV show?". Even when exclusively focusing on
movies, we will compare two or more options on multiple features (genre,
duration, actors, etc.). No movie will clearly win across all dimensions, but
the act of weighting the options will be enough to frustrate us, so that we
will be _less_ satisfied, regardless of what we choose.

Forcing people to make a decision along a trade-off will make them unhappy and
indecisive. When applied to product management, this teaches us that _more
choices are not always better_. With limitless choices we might achieve better
results, but at the cost of significant struggle and energy to sort among the
different options. This is particularly bad for _maximizers_, who, as opposed
to _satisficers_ won't settle for something "_good enough_".

#### Availability bias

Kahneman and Tversky originally termed it [availability _heuristic_][0]
because we take this mental shortcut to save energy: when something is readily
available or very vivid in our memory, we _think_ it is also _frequent_ or
_important_. I prefer calling it a _bias_ because it hinders our ability to
make good decisions _unless_ we take measures to do better.

I think of this bias also when we are blindsided by information or options that
are in front of us, but fail to see that with a bit more digging we would find
much better options.

Availability bias is also why we misestimate facts. For instance:

- That deadly car accidents are more frequent than disease-related deaths (they
  are not).
- Why we tend to form judgements or stereotypes based on extremely small (and
  likely non-representative) samples.
- Why we attribute to our egocentric self more merits or faults than we really
  should.

#### Anchoring

> Hi dad, can I have 100 dollars?
>
> 80 dollars? What do you need 50 dollars for, kid? Here, take 10 and bring
  back some change.

We make decisions based on relativeness and reference points. That is why
anchoring can be powerful or lead to biased decisions. The number we hear first
in a negotiation sets a reference point and we judge what comes next against
it. If someone successfully manages to place an artificial _anchor_, then they
can bias the decision-maker into making that direction.

Some stores seem to always offer a discount on merchandise. The original price
is typically shown prominently and serves as an anchor which makes the
discounted price look like a bargain. In a negotiation, an extreme "opening"
has better odds to the desired outcome than a moderate proposal, closer to
one's true value.

#### Framing

The way information gets presented influences how we make decisions about
it. This is why it is more effective to advertise "a discount on credit cards"
instead of a "surcharge on cash". This is also why when juries are asked to
choose _one_ parent for childcare, they will look for markedly _good_ traits.
If they were asked to _discard_ a parent as being ineligible, they would look
for markedly _bad_ traits.

#### Prospect theory

When faced with the choice of getting \$100 or having a 50% chance of either
getting nothing (\$0) or \$200, most people will choose the sure choice. Even
though they have the same expected value, the "psychological" value of \$200 is
not twice as much as the one from \$100. For this reason, regardless of the
same expected value, people will not take the bet. Things are not symmetrical.
As humans, we tend to be _risk averse_.

There is _diminishing marginal utility_ in satisfaction. This is also why \$100
provide different satisfaction to someone with a thousand and a million dollars
in their bank accounts.

When facing losses, things _do_ work symmetrically, but not the way you would
expect. If asked to surely loose \$100 or flip a coin and either lose nothing
or \$200, most will choose the coin flip. Why? Because losing \$200 does not
hurt twice as much as losing \$100: there is a _decreasing marginal disutility
of losses_.

Lastly, losing \$100 will produce, in absolute terms, a much stronger reaction
than winning \$100. We are _loss averse_. This applies even to small, symbolic
losses as small as a few dollars. Loss aversion also explains why, on average,
few people return products after they have bought them, even if return is free.
They would experience more loss than the pleasure of getting it in the first
place. This is the _endowment effect_.

#### Sunk costs

You are months into an expensive project at work, only to discover that you are
not building the right thing, or that no one will use it. Do you keep working
on it, or do you scrap it? The work or money you have put into is already
_sunk_. Dropping the project would be the right thing to do – completing it,
would not benefit anyone. But loss aversion will sometimes trick us into
continuing that work, worsening an already non-optimal situation.

This recently happened to me. I had invested significant time, money, and
effort into training for a bicycle competition. A few weeks before the race, I
developed a small injury which prevented me from enjoying cycling and put
competitiveness out of the picture. Due to the sunk costs, I considered racing
anyways, almost surely dropping out and, possibly, making the injury worse.
Luckily, I decided to _ignore_ sunk costs and make a decision based on present
conditions. Time and money were already gone and I now had to think about
recovery and future rides.

#### Inversion

This is a tool, not a fallacy, where we think _backward_ rather than _forward_,
succeeding by avoiding mistakes instead of seeking brilliance.

By inverting "_How do I get there?_", picture where you want to _avoid_ going
and then describe what it would take to get there. This is the principle
_inversion_. It helps because it allows us to look at problems differently and
leverage the ability of our minds to _reduce_ and _simplify_ rather than to
_add_. It allows us to first figure out what we would define bad outcomes and
then prune any decision-tree branch that would end up there.

When building proofs by contradiction, mathematicians often use something
similar to inversion. They assume that what they want to prove is false and use
logic to find a contradiction – indicating that what they are trying to prove
is true.

#### The man with the hammer

A Charlie Munger's favorite, this fallacy warns about how having only a limited
set of mental models will encourage you to use the _wrong_ one for the job.
Somehow, this relates to [availability bias](#availability-bias) since
"shinier", more available tools will lure you into thinking they are the most
appropriate.

This is the reason why I am collecting _several_ tools here and why I like
learning from unfamiliar disciplines (e.g., biology, systems thinking,
psychology).

#### Confirmation bias

We often make this mistake when navigating through available facts by
prioritising information that supports _our_ belief (or hypotheses, etc.). This
applies to search, recall, interpretation and "favoring". Essentially, we
select the information that fits outs view of the world.

It typically happens without us realizing it and we fall for it because it
makes us save energy _plus_ it makes us feel good about ourselves. To fight it,
we should first be aware it exists (exactly what we are doing here) and then
try to actively _falsify_ our hypotheses instead of looking for information
that confirm them.

Social media "bubbles" create resonance chambers that make confirmation bias
_insidious_. Social media timelines tend to weigh more shared beliefs, which will
make it more likely for users to only be exposed to other users of the same
"opinions". This compounds the effect of confirmation bias, because it actively
makes it harder to find conflicting information and debate them with others.

#### The hedonic treadmill

As humans, we will adapt to everything. The hedonic treadmill conjectures that
our levels of pleasure, happiness, and sadness will return to a relatively
stable level even after major life events. We "adapt" to those new levels. I
think of it like "mean reversion" (described both in finance and mathematics)
for our feelings.

A few studies have tested this conjecture, finding out that people would return
to their "average" happiness after significant spikes (e.g., when winning the
lottery) or downturns (e.g., falling victims of a debilitating accident).

It has strong pragmatic implications: it will make new things shine less over
time and it might lead to exaggerate (or unconstrained) spending while seeking
additional stimuli – always seeking more.

Knowing about the hedonic treadmill is a powerful way to counteract it. We
should not fool ourselves by thinking that a new purchase (or a promotion, or
more money) will make us happier, because we will quickly adapt to it. Instead,
we can focus on those long-lasting things whose effect compound over time and
bring us meaningfulness and purpose (e.g., social relationship or long-term
missions).

#### Perception of past experiences

We rely on past experiences to make decisions about our future, but we often
misremember and misjudge the past. Our memories of an event rely on:

1. The _absolute high_ (or low) we experienced.
1. What we felt when the experience _ended_.

[This study][1] ingeniously demonstrated this. Two groups of patients underwent
a colonscopy. In one group, the exam was made artificially longer by leaving the
probe still for a few minutes before ending the procedure. Because a still
probe is less unpleasant, the patients fell _less discomfort_ when the
colonscopy ended. As a result, they were _more likely_ to come back for
additional checkups than those in the other group, despite the actual exam
being _longer_ and the absolute discomfort being the same.

#### Incentives

Incentives are powerful system levers and keeping them in mind is fundamental
in decision-making. According to Charlie Munger, we routinely underestimate
their effects on behavior and forget that people will do what they are paid to
do.

In his almanack, Munger tells two stories about incentives. One is the story of
a new Xerox product. Despite being _better_ than older products, it was selling
a lot less. Why? Because salespeople were motivated by outdated incentives,
rewarding them for each sale of an _old_ product.

In another story, FedEx needed packages to move from A to B, every night. The
task was not completed unless _all_ packages had moved. And they needed to move
_fast_! FedEx management tried a whole set of things to incentivize workers.
None worked, until someone realized that workers were paid _by the hour_ and
were lacking incentives to complete their tasks quickly. When they started to
be paid by _shift_, their incentives aligned with FedEx's: to quickly and
effectively complete their tasks before going home.

#### Interest, not reason

> If you would persuade, appeal to interest and not to reason.
>
> Ben Franklin, Poor Richard's Almanack

Rather than pure rationality, we are often motivated by self-interest and
[incentives](#incentives). Sometimes all this happens subconsciously: we
rationalize flawed reasoning without even noticing it.

To change someone's behaviour through _product management_, we need to keep all
this in mind. Instead of trying airtight logic or reasons, build products or
systems that _support_ our users' interest. Only then their behavior will
change.

This has profound implications in business as well. Users won't buy a new
technology because it is shinier, faster, or better than some legacy. They will
only adopt it if it aligns with their interests by letting them save or gain
money.

#### Seven, plus or minus two

Our _working memory_ can hold roughly _seven (± two) "items"_ before
performance declines. Once that happens, we become unable to effectively
_remember_ all the options or even _differentiate_ among them. Grouping
related items together by "chunking" them alleviates the burden on our brains.

This cognitive limitation is also known as [Miller's law][2]. It should impact
the design of products and features by ensuring that we do not overwhelm users
with _more_ than they can effectively work with – remembering that, in the
worst case, five choices will already push them to their limit. Structuring
information in a hierarchy helps. Simplifying the user journey and reducing the
number of choices will do even better.

[0]: https://en.wikipedia.org/wiki/Availability_heuristic
[1]: https://pubmed.ncbi.nlm.nih.gov/12855328/
[2]: https://en.wikipedia.org/wiki/The_Magical_Number_Seven,_Plus_or_Minus_Two
