---
title: 'Nuggets of psychology'
excerpt: >
  TODO
---

Understanding the world requires seeking good explanations, not fooling
oneself, and figuring out _why_ things truly happen. This way, next time we
can do better.

In my quest to achieve all this I have found that many mental models require a
good understanding of psychology. They start there and lead into marketing,
behavioral economics, product management, negotiation, and even how we approach
everyday tasks.

This (living) post collects the nuggets of psychology I wish to remember and
add to my _latticework_ of mental models. I have learned about them across
different books, for instance: _Thinking Fast and Slow_, _The Paradox of
Choice_, and even _Poor Charlie's Almanac_. In describing them here, I will
most likely make simplifications that will make experts shiver. If you have
found something that interests you and you want to deep dive, check out those
books -- or better, the original research that produced these insights. And if
you spot any mistake or over-simplification, please do reach out and let me
know!

<!-- prettier-ignore-start -->

- Table of Contents
{:toc}
<!-- prettier-ignore-end -->

#### The paradox of choice

It is much easier to spend several hours binge-watching a TV series than to
pick a good movie and commit a couple hours to it. Why? Because more freedom of
choices leads to more difficult decisions and, sometimes, to less happiness.

If we have already watched a few episodes of a show, we know what to expect
from it. If we have previously enjoyed it, we expect to continue doing so.
Instead, on modern streaming platforms we need to pick a movie among hundreds.
It is much easier to decide _not_ to pick and just watch a new episode of that
familiar show.

When we do try picking, we face uncertainty and we fear regret: "What if I pick
a worse movie than the TV show?". Even if focusing exclusively on films, to
compare two or more options we will need to evaluate them based on the features
we care about (genre, duration, actors, etc.). Most likely, no clear winner
will emerge, but the act of weighting the options will be enough to frustrate
us, so that we will be _less_ satisfied, regardless of what we choose.

Forcing people on making a decision along a trade-off will make them unhappy
and indecisive. When applying to product management, it teaches us that _more
choices are not always better_. With limitless choices we might achieve better
results, but at the cost of significant struggle and energy to sort among the
different options. This is particularly bad for _maximizers_, who, as opposed
to _satificers_ won't settle for something "good enough".

#### Availability bias

Kahneman and Tversky call it the availability _heuristic_. I prefer to call it
a _bias_ since I believe it hinders our ability to make good decisions, unless
we take measures to do better.

The _heuristic_ is a mental shortcut (we are programmed to take as many as
possible to save energy) and comes from thinking that because something is
readily available or very vivid in our memory, then it is also _frequent_ or
_important_.

Sometimes, I label as availability bias also the fallacy where we are
blindsided by information or options that are readily in front of us, but fail
to see that with a bit more digging we would find much better options.

Availability bias is why we misestimate that deadly car accidents are more
frequent than disease-related deaths (they are not), why we tend to form
judgements or stereotypes based on extremely small samples (possibly
non-representative), and why we attribute to our egocentric self more merits or
faults than we really should.

#### Anchoring

> Hi dad, can I have 100 dollars?
>
> 80 dollars? What do you need 50 dollars for, kid? Here, take 10 and bring
  back some change.

_Anchoring, when it doesn't work._ Described through an example of
[inversion](#inversion).

We make decisions based on relativeness and reference points. That is why
anchoring can be powerful and lead to biased decisions. The number we hear
first sets the reference and we judge what comes next against it. If someone
successfully manages to an artificial _anchor_, then they can bias the
decision-maker into making that direction.

Here are a few examples. Some stores seem to always offer a discount on
merchandise. The original price is typically shown prominently and serves as an
anchor which makes the discounted price look like a bargain. In a negotiation,
an extreme "opening" has better odds to the desired outcome than a moderate
proposal, closer to one's true value.

#### Framing

They way information gets presented will influence how we make decisions about
it. This is why it is more effective to advertise "a discount on credit cards"
instead of a "surcharge on cash". This is also why when juries are asked to
choose _one_ parent for childcare, they will look for markedly _good_ traits.
If they were asked to _discard_ a parent as being ineligible, they would look
for markedly _bad_ traits.

#### Prospect theory

When faced with the choice of getting \$100 or having a 50% chance of either
getting nothing (\$0) or \$200, most people will choose the sure choice. Even
though they have the same expected value, the "psychological" value of \$200 is
not twice as much as the one from \$100. For this reason, regardless of the
same expected value, people will not take the bet. Things are not symmetrical.
As humans, we tend to be _risk averse_.

There is _diminishing marginal utility_ in satisfaction. This is also why \$100
provide different satisfaction to someone with a thousand and a million dollars
in their bank accounts.

When facing losses, things _do_ work symmetrically, but not the way you would
expect. If asked to surely loose \$100 or flip a coin and either lose nothing
or \$200, most will choose the coin flip. Why? Because losing \$200 does not
hurt twice as much as losing \$100: there is a _decreasing marginal disutility
of losses_.

Lastly, losing \$100 will produce, in absolute terms, a much stronger reaction
than winning \$100. We are _loss averse_. This applies even to small, symbolic
losses as small as a few dollars. Loss aversion also explains why, on average,
few people return products after they have bought them, even if return is free.
They would experience more loss than the pleasure of getting it in the first
place. This is the _endowment effect_.

#### Sunk costs

You are months into an expensive project at work, only to discover that you are
not building the right thing, or that no one would use. Do you keep working on
it or you scrap it for something else? All the work or money you have put into
is already _sunk_. Dropping the project would be the right thing to do --
completing it, would not benefit anyone. But loss aversion will sometimes trick
us into continuing that work, worsening an already non-optimal situation.

This happened to me, recently. I had invested significant time, money, and
effort into training for a bicycle competition. A few weeks before the race, I
developed a small injury which prevented me from enjoying cycling and put
competitiveness out of the picture. Due to the sunk costs, I considered racing
anyways, almost surely dropping out and, possibly, making the injury worse.
Luckily, I decided to _ignore_ sunk costs and make a decision based on present
conditions. Time and money were already gone and I now had to think about
recovery and future rides.

#### Inversion

#### The man with the hammer

#### Confirmation bias

#### Interests, not rationality

#### The hedonic treadmill

#### Perception of past experiences
