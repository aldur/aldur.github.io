---
title: 'Nuggets of psychology'
excerpt: >
  TODO
---

Understanding the world requires seeking good explanations, not fooling
oneself, and figuring out _why_ things truly happen. Only this way we can do
better next time.

In my quest to achieve all this, I have found that many mental models require a
good understanding of psychology. They start right there and lean into
marketing, behavioral economics, product management, negotiation, and even how
we approach everyday tasks.

This (living) post collects the nuggets of psychology I wish to remember and
add to my _latticework_ of mental models. I have learned about them from
different books: _Thinking Fast and Slow_, _The Paradox of Choice_, _Poor
Charlie's Almanac_, and probably a lot more. In describing them here, I will
most likely make simplifications that will make experts shiver. If you have
found something that interests you and you want to deep dive, check out those
books – or better, the original research that produced these insights. And if
you spot any mistake or over-simplification, please do reach out and let me
know!

<!-- prettier-ignore-start -->

- Table of Contents
{:toc}
<!-- prettier-ignore-end -->

#### The paradox of choice

It is much easier to spend several hours binge-watching a TV series than to
pick a good movie and commit a couple hours to it. Why? Because freedom of
choice can lead to difficult decisions and, sometimes, to less happiness.

If you have already watched a few episodes of a show, you know what to expect
from it. If you have previously enjoyed it, you expect to continue doing so.
Instead, modern streaming platforms encourage us to pick a movie among
hundreds. It is much easier to decide _not_ to pick and just watch another
episode of that familiar show.

When we do try picking something, we face uncertainty and we fear regret: "What
if I pick a worse movie than the TV show?". Even if focusing exclusively on
movies, comparing two or more options will make us evaluate them based on the
features we care about (genre, duration, actors, etc.). No clear winner will
most likely emerge, but the act of weighting the options will be enough to
frustrate us, so that we will be _less_ satisfied, regardless of what we
choose.

Forcing people to make a decision along a trade-off will make them unhappy and
indecisive. When applied to product management, this teaches us that _more
choices are not always better_. With limitless choices we might achieve better
results, but at the cost of significant struggle and energy to sort among the
different options. This is particularly bad for _maximizers_, who, as opposed
to _satisficers_ won't settle for something "_good enough_".

#### Availability bias

Kahneman and Tversky originally termed it availability _heuristic_ because it
is a mental shortcut that we take to save energy: because something is
readily available or very vivid in our memory, then we _think_ it is also
_frequent_ or _important_. I prefer calling it a _bias_ because I believe it
hinders our ability to make good decisions unless we take measures to do
better.

I think of availability bias also when we are blindsided by information or
options that are readily in front of us, but fail to see that with a bit more
digging we would find much better options.

Availability bias is also why we misestimate facts. For instance:

- That deadly car accidents are more frequent than disease-related deaths (they
  are not).
- Why we tend to form judgements or stereotypes based on extremely small
  samples (possibly non-representative).
- Why we attribute to our egocentric self more merits or faults than we really
  should.

#### Anchoring

> Hi dad, can I have 100 dollars?
>
> 80 dollars? What do you need 50 dollars for, kid? Here, take 10 and bring
  back some change.

_Anchoring, when it doesn't work._

We make decisions based on relativeness and reference points. That is why
anchoring can be powerful or lead to biased decisions. The number we hear first
in a negotiation sets a reference point and we judge what comes next against
it. If someone successfully manages to place an artificial _anchor_, then they
can bias the decision-maker into making that direction.

Here are a few examples. Some stores seem to always offer a discount on
merchandise. The original price is typically shown prominently and serves as an
anchor which makes the discounted price look like a bargain. In a negotiation,
an extreme "opening" has better odds to the desired outcome than a moderate
proposal, closer to one's true value.

#### Framing

They way information gets presented will influence how we make decisions about
it. This is why it is more effective to advertise "a discount on credit cards"
instead of a "surcharge on cash". This is also why when juries are asked to
choose _one_ parent for childcare, they will look for markedly _good_ traits.
If they were asked to _discard_ a parent as being ineligible, they would look
for markedly _bad_ traits.

#### Prospect theory

When faced with the choice of getting \$100 or having a 50% chance of either
getting nothing (\$0) or \$200, most people will choose the sure choice. Even
though they have the same expected value, the "psychological" value of \$200 is
not twice as much as the one from \$100. For this reason, regardless of the
same expected value, people will not take the bet. Things are not symmetrical.
As humans, we tend to be _risk averse_.

There is _diminishing marginal utility_ in satisfaction. This is also why \$100
provide different satisfaction to someone with a thousand and a million dollars
in their bank accounts.

When facing losses, things _do_ work symmetrically, but not the way you would
expect. If asked to surely loose \$100 or flip a coin and either lose nothing
or \$200, most will choose the coin flip. Why? Because losing \$200 does not
hurt twice as much as losing \$100: there is a _decreasing marginal disutility
of losses_.

Lastly, losing \$100 will produce, in absolute terms, a much stronger reaction
than winning \$100. We are _loss averse_. This applies even to small, symbolic
losses as small as a few dollars. Loss aversion also explains why, on average,
few people return products after they have bought them, even if return is free.
They would experience more loss than the pleasure of getting it in the first
place. This is the _endowment effect_.

#### Sunk costs

You are months into an expensive project at work, only to discover that you are
not building the right thing, or that no one would use. Do you keep working on
it or you scrap it for something else? All the work or money you have put into
is already _sunk_. Dropping the project would be the right thing to do –
completing it, would not benefit anyone. But loss aversion will sometimes trick
us into continuing that work, worsening an already non-optimal situation.

This happened to me, recently. I had invested significant time, money, and
effort into training for a bicycle competition. A few weeks before the race, I
developed a small injury which prevented me from enjoying cycling and put
competitiveness out of the picture. Due to the sunk costs, I considered racing
anyways, almost surely dropping out and, possibly, making the injury worse.
Luckily, I decided to _ignore_ sunk costs and make a decision based on present
conditions. Time and money were already gone and I now had to think about
recovery and future rides.

#### Inversion

This is a tool, not a fallacy, where we think _backward_ rather than _forward_,
succeeding by avoiding mistakes instead of seeking brilliance.

By inverting "_How do I get there?_", picture where you want to _avoid_ going
and then describe what it would take to get there. This is the principle
_inversion_. It helps because it allows us to look at problems differently and
leverage the ability of our minds to _reduce_ and _simplify_ rather than to
_add_. It allows us to first figure out what we would define bad outcomes and
then prune any decision-tree branch that would end up there.

When building proofs by contradiction, mathematicians often use something
similar to inversion. They assume that what they want to prove is false and use
logic to find a contradiction – indicating that what they are trying to prove
is true.

#### The man with the hammer

A Munger's favorite, this fallacy warns about how having only a limited set of
mental models will encourage you to use the _wrong_ one for the job. Somehow,
this relates to [availability bias](#availability-bias) since "shinier", more
available tools will lure you into thinking they are the most appropriate.

This is the reason why I am collecting _several_ tools here and why I like
learning from unfamiliar disciplines (e.g., biology, systems thinking,
psychology).

#### Confirmation bias

We often make this mistake when navigating through available facts by
prioritising information that supports _our_ belief (or hypotheses, etc.). This
applies to search, recall, interpretation and "favoring". Essentially, we
select the information that fits outs view of the world.

It typically happens without us realizing it and we fall for it because it
makes us save energy _plus_ it makes us feel good about ourselves. To fight it,
we should first be aware it exists (exactly what we are doing here) and then
try to actively _falsify_ our hypotheses instead of looking for information
that confirm them.

Social media "bubbles" create resonance chambers that make confirmation bias
_insidious_. Social media timelines tend to weigh more shared beliefs, which will
make it more likely for users to only be exposed to other users of the same
"opinions". This compounds the effect of confirmation bias, because it actively
makes it harder to find conflicting information and debate them with others.

#### The hedonic treadmill

As humans, we will adapt to everything. The hedonic treadmill conjecture tells
us that our levels of pleasure, happiness, sadness and of feelings in general
will return to a relatively stable level even after major life events. We
"adapt" to those new levels. I think of it as "mean reversion" (described both
in finance and mathematics) related to feelings.

A few studies have tested this conjecture, finding out that people would return
to their "average" happiness after significant spikes (e.g., when winning the
lottery) or downturns (e.g., falling victims of a debilitating accident).

It has strong pragmatic implications: it will make [new things shine
less](#shiny-new-things) over time and it might lead to exaggerate (or
unconstrained) spending while seeking additional stimuli – always seeking more.

Knowing about the hedonic treadmill is powerful to counteract it. By not
fooling ourselves thinking that a new purchase (or a promotion, or more money)
will make us happier, because we will quickly adapt to it. Instead, by focusing
on those long-lasting things whose effect compound over time and bring us
meaningfulness and purposefulness (e.g., social relationship or long-lasting
missions).

#### Perception of past experiences

We rely on past experiences to make decisions about our future, but we often
misremember and misjudge the past. Our memories of an event rely on:

1. The absolute high (or low) we experienced.
1. What we felt when it ended.

[This study](https://pubmed.ncbi.nlm.nih.gov/12855328/) put this to test and
found out that patients undergoing colonscopy which ended with an additional
period in which

#### Incentives

#### Interest, not reason

> If you would persuade, appeal to interest and not to reason.
>
> Ben Franklin, Poor Richard's Almanack

#### Shiny new things
